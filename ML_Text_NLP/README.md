Environment: IDE: Visual Studio Code, Jupyter notebook, Google Colab; RAM: 16 GB; Processor: 11th Gen Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz.
<br>1.Problem:
<br>Create sentence analysis which includes detection of language, detect parts of speech, syntatic structure and recognition of named entities
<br>2.Challanges:
<br> dependency parsing, 30+ languages support
<br>3.Data preprocessing:
<br> One of the most important steps in this project is text preprocessing. It includes data cleaning, detection of language, segment, understand the language, linguistic perspective
<br> 4.Thoughts on libs:
<br> The choice between libraries is not that broad so I have chosen spaCy and NLTK due to high performance, availability of Named Entity Recognition, excellent support for dependency parsing, community and ecosystems.
<br> 5. Similar ready solutions:
<br> MediaPipe by Google.
<br> 6. Main framework:
<br> The main tech stack would be based on recommendations and my personal experience:
<br> Python 3.11, JSON, Paydantic, Gradio, FastAPI, TensorFlow, NLTK, scikit-learn, Numpy, Pandas, spaCy, MediaPipe
<br> 7. Useful sources:
<br>https://towardsdatascience.com/how-i-trained-a-language-detection-ai-in-20-minutes-with-a-97-accuracy-fdeca0fb7724
<br>https://developers.google.com/mediapipe/solutions/text/language_detector
<br> https://towardsdatascience.com/natural-language-processing-dependency-parsing-cf094bbbe3f7
